## LINE에서 Kafka를 사용하는 방법

[LINE에서 Kafka를 사용하는 방법 – 1편](https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-1/)
[LINE에서 Kafka를 사용하는 방법 – 2편](https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-2/)
[LINE에서 Kafka를 사용하는 방법 – 3편](https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-3/)

> 결국 디스크 읽기 때문에 발생한 지연이 처리 대기 중이던 모든 응답에 영향을 끼치는 상태였습니다. 이 문제를 해결하기 위해 저희는 여러 가지 방법을 고민했는데요. 최종 결론은 원래 차단 대상이 아닌 이벤트 루프가 차단되지 않게 수정하는 방법이었습니다.

> 이를 위해 sendfile이 네트워크 스레드 내에서 호출될 경우 대상 데이터가 반드시 페이지 캐시에 존재하도록 브로커를 개선하기로 했습니다. 방법은 현재 차단(blocking)이 발생한 네트워크 스레드 내에서 이루어지는 디스크 데이터 로딩을 요청 핸들러 스레드 쪽으로 옮기는 것입니다.

> 요청 핸들러 스레드는 하나의 큐를 전체가 폴링(polling)하는 모델이기 때문에 차단이 발생해도 다른 스레드에 전혀 영향을 주지 않아서 다른 스레드는 그동안 계속 후속 요청을 처리할 수 있습니다. 따라서 스레드 하나에서 발생하는 차단은 문제가 되지 않습니다.

> 대상 데이터에 읽기를 호출하면 그 데이터가 디스크에서 로딩된 다음에 사용자 공간의 버퍼에 복사되어 버립니다. 원래 Kafka가 sendfile이라는 시스템 콜을 사용하는 이유는 대량의 데이터 메모리 복사 오버헤드를 피하기 위해서입니다. 이 방법을 사용하면 Kafka가 원래 가지고 있던 매우 효율적인 특성이 사라지게 될 가능성이 있는 거죠. 그래서 다른 방법을 고민해야 했습니다.

> 리눅스 커널은 sendfile이 `/dev/null`을 목적지로 호출되었을 때는 메모리 복사를 하지 않게 구현되어 있습니다. 그래서 디스크에서 페이지 캐시로는 데이터가 로딩되지만 그 이후 메모리 복사는 진행되지 않는, 저희에게 아주 이상적인 동작이었던 것이죠.
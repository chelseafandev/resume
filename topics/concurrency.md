## Logger ì»´í¬ë„ŒíŠ¸ë¥¼ ìœ„í•œ Lock Free íì˜ êµ¬í˜„


https://stackoverflow.com/questions/8735800/implementing-a-lock-free-queue-for-a-logger-component

2012.01.04ì— ë‚˜ì™€ ë¹„ìŠ·í•œ ê³ ë¯¼ì„ í–ˆë˜ ëˆ„êµ°ê°€ê°€ stackoverflowì— ì˜¬ë¦° ê¸€ì„ ê°€ì ¸ì˜´
- producer : consumer = N : 1
- how to implement lock free queue


> I am designing a new improved Logger component (.NET 3.5, C#). I would like to use a lock-free implementation. Logging events will be sent from (potentially) multiple threads, although only aÂ singleÂ thread will do the actual output to file/other storage medium. 

> In essence, all the writers are * enqueuing* their data into some queue, to be retrieves by some other process (LogFileWriter). 

> Can this be achieved in a lock-less manner? i could not find a direct reference to this particular problem on the net.

ì±„íƒëœ ë‹µë³€ì˜ ë‚´ìš©ì€ EnqueueÂ orÂ Dequeue ì—ë§Œ lockì„ ê±¸ì–´ ì‚¬ìš©í•œë‹¤ë©´ ì„±ëŠ¥ì´ ê·¸ë¦¬ ë–¨ì–´ì§€ì§€ëŠ” ì•Šì„ê±°ë¼ê³  ë³´ê³ ìˆìŒ. ë˜í•œ lock free queueì— ë°ì´í„°ê°€ ì±„ì›Œì§€ëŠ” ì†ë„ê°€ ë§¤ìš° ë¹ ë¥¸ ê²½ìš°ë¼ë©´ I/O ì²˜ë¦¬ê°€ ê·¸ ì†ë„ë¥¼ ë”°ë¼ê°€ì§€ ëª»í• ê²ƒìœ¼ë¡œ ì–¸ê¸‰í•˜ê³ ìˆìŒ(lockì´ ì•„ë‹Œ ë‹¤ë¥¸ ë¶€ë¶„ì—ì„œ ë¬¸ì œê°€ ìˆì„ ê°€ëŠ¥ì„±ì„ ì œê¸°í•˜ëŠ”êµ°ğŸ˜¨)

> If you find that using a lock in this case is too slow, you have a much bigger problem. A lock, when it's not contended, takes about 75 nanoseconds on my system (2.0 GHz Core 2 Quad). When it's contended, of course, it's going to take somewhat longer. But since the lock is just protecting a call toÂ EnqueueÂ orÂ Dequeue, it's unlikely that the total time for a log write will be much more than that 75 nanoseconds.

> If the lockÂ isÂ a problem--that is, if you find your threads lining up behind that lock and causing noticeable slowdowns in your application--then it's unlikely that making a lock-free queue is going to help much. Why? Because if you're really writing that much to the log, your lock-free blocking queue is going to fill up so fast you'll be limited to the speed of the I/O subsystem.

> I have a multi-threaded application that writes on the order of 200 log entries a second to aÂ Queue<string>Â that's protected by a simple lock. I've never noticed any significant lock contention, and processing isn't slowed in the least bit. That 75 ns is dwarfed by the time it takes to do everything else.


---

https://qa.ostack.cn/qa/?qa=890294/
êµ¬ê¸€ë§í•˜ë‹¤ë³´ë‹ˆ Boostì˜ lockfree queue ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ STL queueë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ì„±ëŠ¥ì ìœ¼ë¡œ ë–¨ì–´ì¡Œë‹¤ëŠ” ê¸€ì´ ìˆë˜ë° í•œë²ˆ ê°€ì§€ê³  ì™€ë´¤ë‹¤. (2021.10.24ì— ì˜¬ë¼ì˜¨ ê¸€ì´ë‹ˆ ë¹„êµì  ìµœì‹ ì´ë‹¤)

> Until now I was usingÂ std::queueÂ in my project. I measured the average time which a specific operation on this queue requires. The times were measured on 2 machines: My local Ubuntu VM and a remote server. UsingÂ std::queue, the average was almost the same on both machines: ~750 microseconds.

> Then I "upgraded" theÂ std::queueÂ toÂ boost::lockfree::spsc_queue, so I could get rid of the mutexes protecting the queue. On my local VM I could see a huge performance gain, the average is now on 200 microseconds. On the remote machine however, the average went up to 800 microseconds, which is slower than it was before.

> First I thought this might be because the remote machine might not support the lock-free implementation:

> From theÂ Boost.Lockfree page: 
> Not all hardware supports the same set of atomic instructions. If it is not available in hardware, it can be emulated in software using guards. However this has the obvious drawback of losing the lock-free property.

> To find out if these instructions are supported,Â boost::lockfree::queueÂ has a method calledÂ bool is_lock_free(void) const;. However,Â boost::lockfree::spsc_queueÂ does not have a function like this, which, for me, implies that it does not rely on the hardware and that is is always lockfree - on any machine.

> What could be the reason for the performance loss?

ë¹ˆë²ˆí•˜ê²Œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ê²½ìš°ë¼ë©´ Lock free ì•Œê³ ë¦¬ì¦˜ì´ Lock ê¸°ë°˜ì˜ ì•Œê³ ë¦¬ì¦˜ë³´ë‹¤ ì„±ëŠ¥ì ìœ¼ë¡œ ë–¨ì–´ ì§ˆìˆ˜ ìˆë‹¤ëŠ” ë‹µë³€ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. lockì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒìœ¼ë¡œí•´ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì— ëŒ€í•´ì„œ ì–¸ê¸‰í•˜ê³  ìˆìœ¼ë©°, lockì—ì„œ ì™„ì „íˆ freeí•´ì§€ë ¤ê¸°ë³´ë‹¤ëŠ” ê²½ìŸ(lockìœ¼ë¡œ ë³´í˜¸ëœ ë©”ëª¨ë¦¬ì— ì ‘ê·¼í•˜ê³ ì í•˜ëŠ” ì“°ë ˆë“¤ê°„ì˜ ê²½ìŸ)ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆëŠ” ì ì ˆí•œ lockì˜ ìœ„ì¹˜ë¥¼ ê³ ë ¤í•´ë³´ëŠ”ê²Œ ë°”ëŒì§í•œ ë°©ì‹ì¼ ìˆ˜ ìˆë‹¤ê³  ë§í•˜ê³  ìˆë‹¤. 

> Lock free algorithms generally perform more poorly than lock-based algorithms. That's a key reason they're not used nearly as frequently.

> The problem with lock free algorithms is that they maximize contention by allowing contending threads to continue to contend. Locks avoid contention by de-scheduling contending threads. Lock free algorithms, to a first approximation, should only be used when it's not possible to de-schedule contending threads. That only rarely applies to application-level code.

> Let me give you a very extreme hypothetical. Imagine four threads are running on a typical, modern dual-core CPU. Threads A1 and A2 are manipulating collection A. Threads B1 and B2 are manipulating collection B.

> First, let's imagine the collection uses locks. That will mean that if threads A1 and A2 (or B1 and B2) try to run at the same time, one of them will get blocked by the lock. So, very quickly, one A thread and one B thread will be running. These threads will run very quickly and will not contend. Any time threads try to contend, the conflicting thread will get de-scheduled. Yay.

> Now, imagine the collection uses no locks. Now, threads A1 and A2 can run at the same time. This will cause constant contention. Cache lines for the collection will ping-pong between the two cores. Inter-core buses may get saturated. Performance will be awful.

> Again, this is highly exaggerated. But you get the idea. You want to avoid contention, not suffer through as much of it as possible.

> However, now run this thought experiment again where A1 and A2 are the only threads on the entire system. Now, the lock free collection is probably better (though you may find that it's better just to have one thread in that case!).

> Almost every programmer goes through a phase where they think that locks are bad and avoiding locks makes code go faster. Eventually, they realize that it'sÂ contentionÂ that makes things slow and locks, used correctly, minimize contention.